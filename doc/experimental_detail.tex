\section{Experimental detail}
\label{sec:exp_detail}

In what follows we describe the experimental settings used to generate results introduced in \cref{sec:experiments}.

% say we use Jax and geomstats?
% plan on open sourcing?

\paragraph{Architecture}
The architecture of the score network $s_\theta$ is given by a multilayer perceptron with 5 hidden layers with $512$ units each.
We use on sinusoidal activation functions.
% set of divergence free for generating the vector field.

% \paragraph{Loss}
% slide score matching with 1 sample for the Hutchinson estimator.

\paragraph{Optimization}
All models are trained by the stochastic optimizer Adam \citep{kingma2015Adam}
with parameters $\beta_1=0.9$, $\beta_2=0.999$, batch-size of $512$ data-points and a learning rate set to $2e-4$.
% number of iterations
% annealing

\paragraph{Likelihood evaluation}
We rely on the Dormand-Prince solver \citep{dormand1980family}, an adaptive Runge-Kutta 4(5) solver, with absolute and relative tolerance of $1e-5$ to compute approximate numerical solutions of the ODE.
% Models are trained on a cluster of GeForce RTX 2080 Ti GPU cards.